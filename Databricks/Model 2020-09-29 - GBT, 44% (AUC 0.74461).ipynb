{"cells":[{"cell_type":"code","source":["import pyspark.sql.functions as f\n\nfrom pyspark.sql.functions import col, size, split, trim, when"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["#df.unpersist()"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["# Load in one of the tables\ndf1 = spark.sql(\"select * from default.video_games_5\")\ndf2 = spark.sql(\"select * from default.home_and_kitchen_5_small\")\ndf3 = spark.sql(\"select * from default.books_5_small\")\n\ndf = df1.union(df2).union(df3)\n"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["test_df = spark.sql(\"select * from default.reviews_kaggle\")"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["# Convert Unix timestamp to readable date\n\nfrom pyspark.sql.functions import from_unixtime, to_date\n\ndf = df.withColumn(\"reviewTime\", to_date(from_unixtime(df.unixReviewTime))) \\\n                                                .drop(\"unixReviewTime\")\n\ntest_df = test_df.withColumn(\"reviewTime\", to_date(from_unixtime(test_df.unixReviewTime))) \\\n                                                .drop(\"unixReviewTime\")\n\nlastDate = test_df.agg({\"reviewTime\": \"max\"}).collect()[0][0]\nfrom pyspark.sql.functions import lit\n\ndf = df.withColumn('lastDate',lit(lastDate))\ndf = df.withColumn('reviewAge', f.datediff('lastDate', 'reviewTime'))\n\ntest_df = test_df.withColumn('lastDate',lit(lastDate))\ntest_df = test_df.withColumn('reviewAge', f.datediff('lastDate', 'reviewTime'))"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["from pyspark.sql.functions import year\n\ndf = df.withColumn('reviewYear', year('ReviewTime'))\ntest_df = test_df.withColumn('reviewYear', year('ReviewTime'))"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["df = df.filter(col('reviewYear')<2018)\n#There are no reviews in 2018 in the test set"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["#Anything less than 2011 was encoded as 2011\ndf = df.withColumn('Y2011', when(col('reviewYear')<=2011,1).otherwise(0))\ndf = df.withColumn('Y2012', when(col('reviewYear')==2012,1).otherwise(0))\ndf = df.withColumn('Y2013', when(col('reviewYear')==2013,1).otherwise(0))\ndf = df.withColumn('Y2014', when(col('reviewYear')==2014,1).otherwise(0))\ndf = df.withColumn('Y2015', when(col('reviewYear')==2015,1).otherwise(0))\ndf = df.withColumn('Y2016', when(col('reviewYear')==2016,1).otherwise(0))\ndf = df.withColumn('Y2017', when(col('reviewYear')==2017,1).otherwise(0))\n#df = df.withColumn('Y2018', when(col('reviewYear')==2018,1).otherwise(0))\ntest_df = test_df.withColumn('Y2011', when(col('reviewYear')<=2011,1).otherwise(0))\ntest_df = test_df.withColumn('Y2012', when(col('reviewYear')==2012,1).otherwise(0))\ntest_df = test_df.withColumn('Y2013', when(col('reviewYear')==2013,1).otherwise(0))\ntest_df = test_df.withColumn('Y2014', when(col('reviewYear')==2014,1).otherwise(0))\ntest_df = test_df.withColumn('Y2015', when(col('reviewYear')==2015,1).otherwise(0))\ntest_df = test_df.withColumn('Y2016', when(col('reviewYear')==2016,1).otherwise(0))\ntest_df = test_df.withColumn('Y2017', when(col('reviewYear')==2017,1).otherwise(0))\n#test_df = test_df.withColumn('Y2018', when(col('reviewYear')==2018,1).otherwise(0))\n\ndf = df.withColumn('Overall_1', when(col('overall')==1,1).otherwise(0))\ndf = df.withColumn('Overall_2', when(col('overall')==2,1).otherwise(0))\ndf = df.withColumn('Overall_3', when(col('overall')==3,1).otherwise(0))\ndf = df.withColumn('Overall_4', when(col('overall')==4,1).otherwise(0))\ndf = df.withColumn('Overall_5', when(col('overall')==5,1).otherwise(0))\n\ntest_df = test_df.withColumn('Overall_1', when(col('overall')==1,1).otherwise(0))\ntest_df = test_df.withColumn('Overall_2', when(col('overall')==2,1).otherwise(0))\ntest_df = test_df.withColumn('Overall_3', when(col('overall')==3,1).otherwise(0))\ntest_df = test_df.withColumn('Overall_4', when(col('overall')==4,1).otherwise(0))\ntest_df = test_df.withColumn('Overall_5', when(col('overall')==5,1).otherwise(0))\n"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["df = df.withColumn('reviewYear', when(col('reviewYear')<=2011,2011).otherwise(col('reviewYear')))"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["6#df = df.filter(col('reviewYear')>=2012)\n#df = df.sample(False, 0.25, seed=47)\n#df = df.sample(False, 0.10, seed=47)\n#df = df.sampleBy(\"reviewYear\", fractions={2011: 0.012, 2012: 0.009, 2013: 0.026, 2014: 0.046, 2015: 0.060, 2016: 0.077, 2017: 0.070}, seed=47)\n#df = df.sampleBy(\"reviewYear\", fractions={2011: 0.070, 2012: 0.172, 2013: 0.215, 2014: 0.264, 2015: 0.305, 2016: 0.481, 2017: 0.672}, seed=47)\ndf = df.sampleBy(\"reviewYear\", fractions={2011: 0.105, 2012: 0.256, 2013: 0.320, 2014: 0.392, 2015: 0.453, 2016: 0.715, 2017: 1.000}, seed=47)\ndf = df.cache()\n\nprint((df.count(), len(df.columns)))"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(1555345, 26)\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["display(df.select('reviewYear').groupBy('reviewYear').count().orderBy('ReviewYear', ascending=True))"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>reviewYear</th><th>count</th></tr></thead><tbody><tr><td>2011</td><td>61439</td></tr><tr><td>2012</td><td>46533</td></tr><tr><td>2013</td><td>135359</td></tr><tr><td>2014</td><td>240560</td></tr><tr><td>2015</td><td>308759</td></tr><tr><td>2016</td><td>398895</td></tr><tr><td>2017</td><td>363800</td></tr></tbody></table></div>"]}}],"execution_count":11},{"cell_type":"code","source":["df.printSchema()"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- reviewID: long (nullable = true)\n-- overall: double (nullable = true)\n-- vote: integer (nullable = true)\n-- verified: boolean (nullable = true)\n-- reviewTime: date (nullable = true)\n-- reviewerID: string (nullable = true)\n-- asin: string (nullable = true)\n-- reviewerName: string (nullable = true)\n-- reviewText: string (nullable = true)\n-- summary: string (nullable = true)\n-- label: integer (nullable = true)\n-- lastDate: date (nullable = false)\n-- reviewAge: integer (nullable = true)\n-- reviewYear: integer (nullable = true)\n-- Y2011: integer (nullable = false)\n-- Y2012: integer (nullable = false)\n-- Y2013: integer (nullable = false)\n-- Y2014: integer (nullable = false)\n-- Y2015: integer (nullable = false)\n-- Y2016: integer (nullable = false)\n-- Y2017: integer (nullable = false)\n-- Overall_1: integer (nullable = false)\n-- Overall_2: integer (nullable = false)\n-- Overall_3: integer (nullable = false)\n-- Overall_4: integer (nullable = false)\n-- Overall_5: integer (nullable = false)\n\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["# For our intitial modeling efforts, we are not going to use the following features\ndrop_list = ['asin', 'reviewID', 'reviewerID','reviewTime', 'image', 'style', 'reviewerName']\ndf = df.select([column for column in df.columns if column not in drop_list])\ndf = df.na.drop(subset=[\"reviewText\", \"label\"])\ndf.show(5)\nprint((df.count(), len(df.columns)))"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+----+--------+--------------------+--------------------+-----+----------+---------+----------+-----+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+\noverall|vote|verified|          reviewText|             summary|label|  lastDate|reviewAge|reviewYear|Y2011|Y2012|Y2013|Y2014|Y2015|Y2016|Y2017|Overall_1|Overall_2|Overall_3|Overall_4|Overall_5|\n+-------+----+--------+--------------------+--------------------+-----+----------+---------+----------+-----+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+\n    5.0|   0|    true|This game is a bi...|but when you do i...|    0|2017-12-31|      806|      2015|    0|    0|    0|    0|    1|    0|    0|        0|        0|        0|        0|        1|\n    4.0|   0|   false|I played it a whi...|But in spite of t...|    0|2017-12-31|      888|      2015|    0|    0|    0|    0|    1|    0|    0|        0|        0|        0|        1|        0|\n    5.0|   0|    true|I bought this gam...|A very good game ...|    0|2017-12-31|     1399|      2014|    0|    0|    0|    1|    0|    0|    0|        0|        0|        0|        0|        1|\n    5.0|   0|    true|I have played the...|Anno 2070 more li...|    0|2017-12-31|     1409|      2014|    0|    0|    0|    1|    0|    0|    0|        0|        0|        0|        0|        1|\n    4.0|   0|    true|4 Stars because t...|My boys enjoys th...|    0|2017-12-31|     1829|      2012|    0|    1|    0|    0|    0|    0|    0|        0|        0|        0|        1|        0|\n+-------+----+--------+--------------------+--------------------+-----+----------+---------+----------+-----+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+\nonly showing top 5 rows\n\n(1555345, 21)\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":["#https://stackoverflow.com/questions/51450004/spark-dataframe-python-count-substring-in-string\n#There are some cases where there are more spaces than characters. These give negative numbers. We will replace with 0\ndf = df.withColumn('word_count', f.size(f.split(f.col('reviewText'), ' ')))\ndf = df.withColumn('character_count',  when((f.length(trim(col('reviewText'))) - size(split(trim(col(\"reviewText\")), \" \")) - 1)<0,0).otherwise(f.length(trim(col('reviewText'))) - size(split(trim(col(\"reviewText\")), \" \")) - 1))\ndf = df.withColumn('sentence_count', f.size(f.split(f.col('reviewText'), r\"\\.\")))\ndf = df.withColumn('avg_word_length', f.col('character_count')/f.col('word_count'))\ndf = df.withColumn('avg_sentence_length', f.col('word_count')/f.col('sentence_count'))"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["df = df.withColumn('sum_word_count', f.size(f.split(f.col('summary'), ' ')))\ndf = df.withColumn('sum_character_count',  when((f.length(trim(col('summary'))) - size(split(trim(col(\"summary\")), \" \")) - 1)<0,0).otherwise(f.length(trim(col('summary'))) - size(split(trim(col(\"summary\")), \" \")) - 1))\ndf = df.fillna(0, subset=['sum_character_count'])\ndf = df.withColumn('sum_sentence_count', f.size(f.split(f.col('summary'), r\"\\.\")))\ndf = df.withColumn('sum_avg_word_length', f.col('character_count')/f.col('word_count'))\ndf = df.withColumn('sum_avg_sentence_length', f.col('word_count')/f.col('sentence_count'))"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":15},{"cell_type":"code","source":["from textblob import TextBlob\ndef sentiment_score(chat):\n    return TextBlob(chat).sentiment.polarity\n  \nfrom pyspark.sql.types import FloatType\nsentiment_score_udf = f.udf(lambda x: sentiment_score(x), FloatType())"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"code","source":["df = df.withColumn('sentiment_score',sentiment_score_udf('reviewText'))\ntest_df = test_df.withColumn('sentiment_score',sentiment_score_udf('reviewText'))"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":17},{"cell_type":"code","source":["from pyspark.sql.types import FloatType\n\n# Re-balancing (weighting) of records to be used in the logistic loss objective function\nnumPositives = df.filter(df[\"label\"] == 1).count()\ndatasetSize = df.count()\nbalancingRatio = (datasetSize - numPositives) / datasetSize\nprint(\"numPositives   = {}\".format(numPositives))\nprint(\"datasetSize    = {}\".format(datasetSize))\nprint(\"balancingRatio = {}\".format(balancingRatio))\n\ndef calculateWeights(d, multiplier = 1):\n    if d == 1.0:\n      return multiplier * balancingRatio\n    else:\n      return (1.0 - balancingRatio)\n    \nudfcalculateWeights = f.udf(calculateWeights, FloatType())\n    \ndf = df.withColumn(\"classWeightCol\", udfcalculateWeights(df[\"label\"]))"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">numPositives   = 180220\ndatasetSize    = 1555345\nbalancingRatio = 0.884128601692872\n</div>"]}}],"execution_count":18},{"cell_type":"code","source":["#http://michael-harmon.com/blog/SentimentAnalysisP2.html#bullet5\nfrom pyspark import keyword_only\nimport pyspark.sql.functions as F\nfrom pyspark.sql import DataFrame\nfrom pyspark.sql.types import ArrayType, StringType\nfrom pyspark.ml import Transformer\nfrom pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param\nimport nltk\nfrom nltk.stem.porter import PorterStemmer\n\n\nclass PorterStemming(Transformer, HasInputCol, HasOutputCol):\n    \"\"\"\n    PosterStemming class using the NLTK Porter Stemmer\n    \n    This comes from https://stackoverflow.com/questions/32331848/create-a-custom-transformer-in-pyspark-ml\n    Adapted to work with the Porter Stemmer from NLTK.\n    \"\"\"\n    \n    @keyword_only\n    def __init__(self, \n                 inputCol  : str = None, \n                 outputCol : str = None, \n                 min_size  : int = None):\n        \"\"\"\n        Constructor takes in the input column name, output column name,\n        plus the minimum legnth of a token (min_size)\n        \"\"\"\n        # call Transformer classes constructor since were extending it.\n        super(Transformer, self).__init__()\n\n        # set Parameter objects minimum token size\n        self.min_size = Param(self, \"min_size\", \"\")\n        self._setDefault(min_size=0)\n\n        # set the input keywork arguments\n        kwargs = self._input_kwargs\n        self.setParams(**kwargs)\n\n        # initialize Stemmer object\n        self.stemmer  = PorterStemmer()\n\n        \n    @keyword_only\n    def setParams(self, \n                  inputCol  : str = None, \n                  outputCol : str = None, \n                  min_size  : int = None\n      ) -> None:\n        \"\"\"\n        Function to set the keyword arguemnts\n        \"\"\"\n        kwargs = self._input_kwargs\n        return self._set(**kwargs)\n    \n\n    def _stem_func(self, words  : list) -> list:\n        \"\"\"\n        Stemmer function call that performs stemming on a\n        list of tokens in words and returns a list of tokens\n        that have meet the minimum length requiremnt.\n        \"\"\"\n        # We need a way to get min_size and cannot access it \n        # with self.min_size\n        min_size       = self.getMinSize()\n\n        # stem that actual tokens by applying \n        # self.stemmer.stem function to each token in \n        # the words list\n        stemmed_words  = map(self.stemmer.stem, words)\n\n        # now create the new list of tokens from\n        # stemmed_words by filtering out those\n        # that are not of legnth > min_size\n        filtered_words = filter(lambda x: len(x) > min_size, stemmed_words)\n\n        return list(filtered_words)\n    \n    def _transform(self, df: DataFrame) -> DataFrame:\n        \"\"\"\n        Transform function is the method that is called in the \n        MLPipleline.  We have to override this function for our own use\n        and have it call the _stem_func.\n\n        Notice how it takes in a type DataFrame and returns type Dataframe\n        \"\"\"\n        # Get the names of the input and output columns to use\n        out_col       = self.getOutputCol()\n        in_col        = self.getInputCol()\n\n        # create the stemming function UDF by wrapping the stemmer \n        # method function\n        stem_func_udf = F.udf(self._stem_func, ArrayType(StringType()))\n        \n        # now apply that UDF to the column in the dataframe to return\n        # a new column that has the same list of words after being stemmed\n        df2           = df.withColumn(out_col, stem_func_udf(df[in_col]))\n\n        return df2\n  \n  \n    def setMinSize(self,value):\n        \"\"\"\n        This method sets the minimum size value\n        for the _paramMap dictionary.\n        \"\"\"\n        self._paramMap[self.min_size] = value\n        return self\n\n    def getMinSize(self) -> int:\n        \"\"\"\n        This method uses the parent classes (Transformer)\n        .getOrDefault method to get the minimum\n        size of a token.\n        \"\"\"\n        return self.getOrDefault(self.min_size)\n"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":19},{"cell_type":"code","source":["df.show(5)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+----+--------+--------------------+--------------------+-----+----------+---------+----------+-----+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+----------+---------------+--------------+------------------+-------------------+--------------+-------------------+------------------+-------------------+-----------------------+---------------+--------------+\noverall|vote|verified|          reviewText|             summary|label|  lastDate|reviewAge|reviewYear|Y2011|Y2012|Y2013|Y2014|Y2015|Y2016|Y2017|Overall_1|Overall_2|Overall_3|Overall_4|Overall_5|word_count|character_count|sentence_count|   avg_word_length|avg_sentence_length|sum_word_count|sum_character_count|sum_sentence_count|sum_avg_word_length|sum_avg_sentence_length|sentiment_score|classWeightCol|\n+-------+----+--------+--------------------+--------------------+-----+----------+---------+----------+-----+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+----------+---------------+--------------+------------------+-------------------+--------------+-------------------+------------------+-------------------+-----------------------+---------------+--------------+\n    5.0|   0|    true|This game is a bi...|but when you do i...|    0|2017-12-31|      806|      2015|    0|    0|    0|    0|    1|    0|    0|        0|        0|        0|        0|        1|        17|             53|             2|3.1176470588235294|                8.5|             6|                 20|                 2| 3.1176470588235294|                    8.5|    0.036111113|     0.1158714|\n    4.0|   0|   false|I played it a whi...|But in spite of t...|    0|2017-12-31|      888|      2015|    0|    0|    0|    0|    1|    0|    0|        0|        0|        0|        1|        0|        66|            230|             6| 3.484848484848485|               11.0|            11|                 31|                 1|  3.484848484848485|                   11.0|     0.08981481|     0.1158714|\n    5.0|   0|    true|I bought this gam...|A very good game ...|    0|2017-12-31|     1399|      2014|    0|    0|    0|    1|    0|    0|    0|        0|        0|        0|        0|        1|       148|            560|             6|3.7837837837837838| 24.666666666666668|            11|                 43|                 1| 3.7837837837837838|     24.666666666666668|    -0.10854342|     0.1158714|\n    5.0|   0|    true|I have played the...|Anno 2070 more li...|    0|2017-12-31|     1409|      2014|    0|    0|    0|    1|    0|    0|    0|        0|        0|        0|        0|        1|       172|            718|            11| 4.174418604651163| 15.636363636363637|             6|                 22|                 1|  4.174418604651163|     15.636363636363637|    0.031944446|     0.1158714|\n    4.0|   0|    true|4 Stars because t...|My boys enjoys th...|    0|2017-12-31|     1829|      2012|    0|    1|    0|    0|    0|    0|    0|        0|        0|        0|        1|        0|        30|            117|             3|               3.9|               10.0|             6|                 28|                 1|                3.9|                   10.0|   -0.108333334|     0.1158714|\n+-------+----+--------+--------------------+--------------------+-----+----------+---------+----------+-----+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+----------+---------------+--------------+------------------+-------------------+--------------+-------------------+------------------+-------------------+-----------------------+---------------+--------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":20},{"cell_type":"code","source":["# In Spark's MLLib, it's considered good practice to combine all the preprocessing steps into a pipeline.\n# That way, you can run the same steps on both the training data, and testing data and beyond (new data)\n# without copying and pasting any code.\n\n# It is possible to run all of these steps one-by-one, outside of a Pipeline, if desired. But that's\n# not how I am going to do it here.\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, VectorAssembler, IDF, NGram\nfrom pyspark.ml.classification import LogisticRegression, RandomForestClassifier, NaiveBayes\nfrom pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel\nfrom pyspark.ml.classification import GBTClassifier\n#https://medium.com/@aieeshashafique/gradient-boost-model-using-pyspark-mllib-solving-a-chronic-kidney-disease-problem-13039b6dc099\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.feature import OneHotEncoder\nfrom pyspark.ml.feature import OneHotEncoderEstimator\n\n# We'll tokenize the text using a simple RegexTokenizer\ntokenizer = RegexTokenizer(inputCol=\"reviewText\", outputCol=\"words\", pattern=\"\\\\W\")\n\n# Remove standard Stopwords\nstopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n\n# TODO: insert other clearning steps here (and put into the pipeline, of course!)\n# E.g., n-grams? document length?\n\n\n#stem = PorterStemming(inputCol=\"filtered\", outputCol=\"stemmed\")\nbigram = NGram(inputCol=\"filtered\", outputCol=\"bigrams\", n=2)\n#assembler_ngram = VectorAssembler(inputCols=['filtered', 'bigrams'], outputCol='combined')\n\n# Vectorize the sentences using simple BOW method. Other methods are possible:\n# https://spark.apache.org/docs/2.2.0/ml-features.html#feature-extractors\n\ntf = CountVectorizer(inputCol=\"bigrams\", outputCol=\"rawFeatures\", vocabSize=2000, minTF=1, maxDF=0.40)\n# Generate Inverse Document Frequency weighting\nidf = IDF(inputCol=\"rawFeatures\", outputCol=\"idfFeatures\", minDocFreq=100)\n\n#tokenizer_sum = RegexTokenizer(inputCol=\"summary\", outputCol=\"words_sum\", pattern=\"\\\\W\")\n#stopwordsRemover_sum = StopWordsRemover(inputCol=\"words_sum\", outputCol=\"filtered_sum\")\n#bigram_sum = NGram(inputCol=\"filtered_sum\", outputCol=\"bigrams_sum\", n=2)\n#tf_sum = CountVectorizer(inputCol=\"bigrams_sum\", outputCol=\"rawFeatures_sum\", vocabSize=2000, minTF=1, maxDF=0.40)\n#idf_sum = IDF(inputCol=\"rawFeatures_sum\", outputCol=\"idfFeatures_sum\", minDocFreq=100)\n\n#one-hot-encoder\n#encode_overall = OneHotEncoder(inputCol=\"overall\", outputCol=\"overall_ohe\")\n#encode_year = OneHotEncoderEstimator(inputCols=[\"reviewYear\"], outputCols=[\"year_ohe\"], handleInvalid=\"keep\")\n# Combine all features into one final \"features\" column\n#assembler = VectorAssembler(inputCols=['character_count','word_count','sentence_count','avg_word_length','avg_sentence_length', 'reviewAge', \"verified\", \"Y2011\", \"Y2012\", \"Y2013\", \"Y2014\", \"Y2015\", \"Y2016\", \"Y2017\", \"Y2018\",\n#                                       \"Overall_1\", \"Overall_2\", \"Overall_3\", \"Overall_4\", \"Overall_5\", \"idfFeatures\", \"idfFeatures_sum\"], outputCol=\"features\")\n#assembler = VectorAssembler(inputCols=['character_count','word_count','sentence_count','avg_word_length','avg_sentence_length', 'reviewAge', \"verified\", \"Y2011\", \"Y2012\", \"Y2013\", \"Y2014\", \"Y2015\", \"Y2016\", \"Y2017\", \"Y2018\",\n#                                       \"Overall_1\", \"Overall_2\", \"Overall_3\", \"Overall_4\", \"Overall_5\", \"idfFeatures\"], outputCol=\"features\")\nassembler = VectorAssembler(inputCols=['character_count','word_count','sentence_count','avg_word_length','avg_sentence_length', 'reviewAge', \"verified\", \"Y2011\", \"Y2012\", \"Y2013\", \"Y2014\", \"Y2015\", \"Y2016\", \"Y2017\",\n                                       \"Overall_1\", \"Overall_2\", \"Overall_3\", \"Overall_4\", \"Overall_5\", \"sentiment_score\", 'sum_word_count', 'sum_character_count', 'sum_sentence_count', 'sum_avg_word_length', 'sum_avg_sentence_length', \"idfFeatures\"], outputCol=\"features\")\n\n# Machine Learning Algorithm\n\n#ml_alg  = LogisticRegression(maxIter=10, weightCol=\"classWeightCol\")\n#ml_alg  = NaiveBayes(modelType=\"multinomial\", weightCol=\"classWeightCol\")\nml_alg = GBTClassifier()\n#ml_alg  = RandomForestClassifier(numTrees=100, featureSubsetStrategy=\"auto\", impurity='gini', maxDepth=4, maxBins=32)\n\n\n#pipeline = Pipeline(stages=[tokenizer, stopwordsRemover, stem, bigram, tf, idf, encoder, assembler, ml_alg])\npipeline = Pipeline(stages=[tokenizer, stopwordsRemover, bigram, tf, idf, assembler, ml_alg])\n\n#paramGrid = ParamGridBuilder() \\\n#    .addGrid(ml_alg.regParam, [0.0, 0.19]) \\\n#    .addGrid(ml_alg.elasticNetParam, [0.0, 0.5]) \\\n#    .build()\n\n#paramGrid = ParamGridBuilder() \\\n#    .addGrid(ml_alg.smoothing, [0.0, 0.5, 1.0, 1.5]) \\\n#    .build()\n\nparamGrid = ParamGridBuilder() \\\n    .addGrid(ml_alg.maxIter, [30,40]) \\\n    .build()\n\nevaluator = BinaryClassificationEvaluator(metricName=\"areaUnderROC\")\n\ncrossval = CrossValidator(estimator=pipeline,\n                          estimatorParamMaps=paramGrid,\n                          evaluator=evaluator,\n                          numFolds=2)  # use 3+ folds in practice"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":21},{"cell_type":"code","source":["# set seed for reproducibility\n(trainingData, testData) = df.randomSplit([0.9, 0.1], seed = 47)\nprint(\"Training Dataset Count: \" + str(trainingData.count()))\nprint(\"Test Dataset Count:     \" + str(testData.count()))"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training Dataset Count: 1399978\nTest Dataset Count:     155367\n</div>"]}}],"execution_count":22},{"cell_type":"code","source":["pipelineFit = crossval.fit(trainingData)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">MLlib will automatically track trials in MLflow. After your tuning fit() call has completed, view the MLflow UI to see logged runs.\n</div>"]}}],"execution_count":23},{"cell_type":"code","source":["predictions =  pipelineFit.transform(testData)\npredictions.groupBy(\"prediction\").count().show()"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+------+\nprediction| count|\n+----------+------+\n       0.0|148193|\n       1.0|  7174|\n+----------+------+\n\n</div>"]}}],"execution_count":24},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n\nacc_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\npre_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\nrec_evaluator = MulticlassClassificationEvaluator(metricName=\"weightedRecall\")\npr_evaluator  = BinaryClassificationEvaluator(metricName=\"areaUnderPR\")\nauc_evaluator = BinaryClassificationEvaluator(metricName=\"areaUnderROC\")\n\nprint(\"Test Accuracy       = %g\" % (acc_evaluator.evaluate(predictions)))\nprint(\"Test Precision      = %g\" % (pre_evaluator.evaluate(predictions)))\nprint(\"Test Recall         = %g\" % (rec_evaluator.evaluate(predictions)))\nprint(\"Test areaUnderPR    = %g\" % (pr_evaluator.evaluate(predictions)))\nprint(\"Test areaUnderROC   = %g\" % (auc_evaluator.evaluate(predictions)))"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Test Accuracy       = 0.896374\nTest Precision      = 0.87753\nTest Recall         = 0.896374\nTest areaUnderPR    = 0.492858\nTest areaUnderROC   = 0.859349\n</div>"]}}],"execution_count":25},{"cell_type":"code","source":["# Load in the tables\n\ntest_df.show(5)\nprint((test_df.count(), len(test_df.columns)))\ntest_df.describe().show()"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+-------+--------+----------+--------------+----------+----------------+--------------------+--------------------+----------+---------+----------+-----+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+---------------+\nreviewID|overall|verified|reviewTime|    reviewerID|      asin|    reviewerName|          reviewText|             summary|  lastDate|reviewAge|reviewYear|Y2011|Y2012|Y2013|Y2014|Y2015|Y2016|Y2017|Overall_1|Overall_2|Overall_3|Overall_4|Overall_5|sentiment_score|\n+--------+-------+--------+----------+--------------+----------+----------------+--------------------+--------------------+----------+---------+----------+-----+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+---------------+\n67000000|      3|    true|2012-05-16|A3IXM075VM1P9T|B007JYB3O2|         nachtik|I would say these...|     average reading|2017-12-31|     2055|      2012|    0|    1|    0|    0|    0|    0|    0|        0|        0|        1|        0|        0|      0.2595238|\n67000001|      5|    true|2012-12-25|A3LGZ7A3WSV3JJ| 985719745|             MSP|WOW, DROPPIN DIME...|WOW.................|2017-12-31|     1832|      2012|    0|    1|    0|    0|    0|    0|    0|        0|        0|        0|        0|        1|    0.093333334|\n67000002|      5|    true|2012-09-18|A3BF5G7CJNIAG0|B002KXH7PQ|    C. S. DeMore|You&#39;ll love the p...|Another Buggy Bar...|2017-12-31|     1930|      2012|    0|    1|    0|    0|    0|    0|    0|        0|        0|        0|        0|        1|       0.309375|\n67000003|      5|   false|2015-07-27|A2W41RTHSHYC4Q|B011LXVWRO|           Light|For the majority ...|This is a complet...|2017-12-31|      888|      2015|    0|    0|    0|    0|    1|    0|    0|        0|        0|        0|        0|        1|     0.32205883|\n67000004|      5|   false|2003-03-29| ACTBQZV1CJ9E8|9706061681|Richard Eastwood|MI MEJOR AMIGO..Q...|LE ACABA DE SUCED...|2017-12-31|     5391|      2003|    1|    0|    0|    0|    0|    0|    0|        0|        0|        0|        0|        1|        -0.4375|\n+--------+-------+--------+----------+--------------+----------+----------------+--------------------+--------------------+----------+---------+----------+-----+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+---------------+\nonly showing top 5 rows\n\n(304984, 25)\n+-------+----------------+------------------+--------------------+--------------------+--------------------+--------------------+------------------+-----------------+------------------+--------------------+--------------------+-------------------+-------------------+------------------+------------------+------------------+--------------------+-------------------+------------------+-------------------+------------------+-------------------+\nsummary|        reviewID|           overall|          reviewerID|                asin|        reviewerName|          reviewText|           summary|        reviewAge|        reviewYear|               Y2011|               Y2012|              Y2013|              Y2014|             Y2015|             Y2016|             Y2017|           Overall_1|          Overall_2|         Overall_3|          Overall_4|         Overall_5|    sentiment_score|\n+-------+----------------+------------------+--------------------+--------------------+--------------------+--------------------+------------------+-----------------+------------------+--------------------+--------------------+-------------------+-------------------+------------------+------------------+------------------+--------------------+-------------------+------------------+-------------------+------------------+-------------------+\n  count|          304984|            304984|              304984|              304984|              304846|              304984|            304855|           304984|            304984|              304984|              304984|             304984|             304984|            304984|            304984|            304984|              304984|             304984|            304984|             304984|            304984|             304984|\n   mean|    6.71524915E7|  4.32360058232563|                null|2.3012381768059964E9|1.2594881926923077E8|1.541666666666666...|14364.488500000001|887.4275273456968|2015.0393528840857|0.039044671195866014|0.029873698292369435|0.08749311439288618|0.15473598615009312|0.1983677832279726|0.2566823177609317|0.2338024289798809|0.039907011515358186|0.03981192455997692|0.0897653647404454|0.21780486845211552| 0.612710830732104| 0.2758891461719976|\n stddev|88041.4415867134|1.0564910412520399|                null|2.1914585491320453E9| 9.906705755265955E8|3.776296686790733E21| 90140.69312527789|748.4511948178172|2.0293887473522956|  0.1937015949106458|  0.1702391126284671|0.28255677501251397| 0.3616534108685826| 0.398771271789687|0.4368033094048113|0.4232486746065875|  0.1957410727859513| 0.1955174175463859|0.2858457834951916| 0.4127547290323331|0.4871314470444298|0.25603968280643635|\n    min|        67000000|                 1|A001170867ZBE9FORRQL|          000612321X|             \u001A Rae \u001A|                    |                  |                0|              1997|                   0|                   0|                  0|                  0|                 0|                 0|                 0|                   0|                  0|                 0|                  0|                 0|               -1.0|\n    max|        67304983|                 5|       AZZYKHA63LQ7A|          B01HJEKGHQ|             ~~ Mari|~~~I received an ...| ~~~~3.5 Stars~~~~|             7349|              2017|                   1|                   1|                  1|                  1|                 1|                 1|                 1|                   1|                  1|                 1|                  1|                 1|                1.0|\n+-------+----------------+------------------+--------------------+--------------------+--------------------+--------------------+------------------+-----------------+------------------+--------------------+--------------------+-------------------+-------------------+------------------+------------------+------------------+--------------------+-------------------+------------------+-------------------+------------------+-------------------+\n\n</div>"]}}],"execution_count":26},{"cell_type":"code","source":["test_df = test_df.withColumn('word_count', f.size(f.split(f.col('reviewText'), ' ')))\ntest_df = test_df.withColumn('character_count',  when((f.length(trim(col('reviewText'))) - size(split(trim(col(\"reviewText\")), \" \")) - 1)<0,0).otherwise(f.length(trim(col('reviewText'))) - size(split(trim(col(\"reviewText\")), \" \")) - 1))\ntest_df = test_df.withColumn('sentence_count', f.size(f.split(f.col('reviewText'), r\"\\.\")))\ntest_df = test_df.withColumn('avg_word_length', f.col('character_count')/f.col('word_count'))\ntest_df = test_df.withColumn('avg_sentence_length', f.col('word_count')/f.col('sentence_count'))\n\n"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":27},{"cell_type":"code","source":["test_df = test_df.withColumn('sum_word_count', f.size(f.split(F.col('summary'), ' ')))\ntest_df = test_df.withColumn('sum_character_count',  when((f.length(trim(col('summary'))) - size(split(trim(col(\"summary\")), \" \")) - 1)<0,0).otherwise(f.length(trim(col('summary'))) - size(split(trim(col(\"summary\")), \" \")) - 1))\ntest_df = test_df.fillna(0, subset=['sum_character_count'])\ntest_df = test_df.withColumn('sum_sentence_count', f.size(f.split(F.col('summary'), r\"\\.\")))\ntest_df = test_df.withColumn('sum_avg_word_length', f.col('character_count')/f.col('word_count'))\ntest_df = test_df.withColumn('sum_avg_sentence_length', f.col('word_count')/f.col('sentence_count'))"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":28},{"cell_type":"code","source":["kaggle_pred = pipelineFit.transform(test_df)\nkaggle_pred.show(5)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+-------+--------+----------+--------------+----------+----------------+--------------------+--------------------+----------+---------+----------+-----+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+---------------+----------+---------------+--------------+-----------------+-------------------+--------------+-------------------+------------------+-------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\nreviewID|overall|verified|reviewTime|    reviewerID|      asin|    reviewerName|          reviewText|             summary|  lastDate|reviewAge|reviewYear|Y2011|Y2012|Y2013|Y2014|Y2015|Y2016|Y2017|Overall_1|Overall_2|Overall_3|Overall_4|Overall_5|sentiment_score|word_count|character_count|sentence_count|  avg_word_length|avg_sentence_length|sum_word_count|sum_character_count|sum_sentence_count|sum_avg_word_length|sum_avg_sentence_length|               words|            filtered|             bigrams|         rawFeatures|         idfFeatures|            features|       rawPrediction|         probability|prediction|\n+--------+-------+--------+----------+--------------+----------+----------------+--------------------+--------------------+----------+---------+----------+-----+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+---------------+----------+---------------+--------------+-----------------+-------------------+--------------+-------------------+------------------+-------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n67000000|      3|    true|2012-05-16|A3IXM075VM1P9T|B007JYB3O2|         nachtik|I would say these...|     average reading|2017-12-31|     2055|      2012|    0|    1|    0|    0|    0|    0|    0|        0|        0|        1|        0|        0|      0.2595238|        47|            213|             4|4.531914893617022|              11.75|             2|                 12|                 1|  4.531914893617022|                  11.75|[i, would, say, t...|[say, 5, regular,...|[say 5, 5 regular...|(2000,[11,820,151...|(2000,[11,820,151...|(2025,[0,1,2,3,4,...|[0.64931120041034...|[0.78560304406352...|       0.0|\n67000001|      5|    true|2012-12-25|A3LGZ7A3WSV3JJ| 985719745|             MSP|WOW, DROPPIN DIME...|WOW.................|2017-12-31|     1832|      2012|    0|    1|    0|    0|    0|    0|    0|        0|        0|        0|        0|        1|    0.093333334|       132|            596|            21|4.515151515151516|  6.285714285714286|             1|                 18|                18|  4.515151515151516|      6.285714285714286|[wow, droppin, di...|[wow, droppin, di...|[wow droppin, dro...| (2000,[1193],[1.0])|(2000,[1193],[7.2...|(2025,[0,1,2,3,4,...|[0.25307548276867...|[0.62390373839294...|       0.0|\n67000002|      5|    true|2012-09-18|A3BF5G7CJNIAG0|B002KXH7PQ|    C. S. DeMore|You&#39;ll love the p...|Another Buggy Bar...|2017-12-31|     1930|      2012|    0|    1|    0|    0|    0|    0|    0|        0|        0|        0|        0|        1|       0.309375|        44|            189|             2|4.295454545454546|               22.0|             4|                 21|                 1|  4.295454545454546|                   22.0|[you, ll, love, t...|[ll, love, patter...|[ll love, love pa...|(2000,[74,146,571...|(2000,[74,146,571...|(2025,[0,1,2,3,4,...|[0.80690692698122...|[0.83394021679277...|       0.0|\n67000003|      5|   false|2015-07-27|A2W41RTHSHYC4Q|B011LXVWRO|           Light|For the majority ...|This is a complet...|2017-12-31|      888|      2015|    0|    0|    0|    0|    1|    0|    0|        0|        0|        0|        0|        1|     0.32205883|       160|            736|            10|              4.6|               16.0|             8|                 35|                 1|                4.6|                   16.0|[for, the, majori...|[majority, person...|[majority persons...|(2000,[287,670],[...|(2000,[287,670],[...|(2025,[0,1,2,3,4,...|[0.50098717744933...|[0.73144658323304...|       0.0|\n67000004|      5|   false|2003-03-29| ACTBQZV1CJ9E8|9706061681|Richard Eastwood|MI MEJOR AMIGO..Q...|LE ACABA DE SUCED...|2017-12-31|     5391|      2003|    1|    0|    0|    0|    0|    0|    0|        0|        0|        0|        0|        1|        -0.4375|        84|            363|             8|4.321428571428571|               10.5|             9|                 28|                 1|  4.321428571428571|                   10.5|[mi, mejor, amigo...|[mi, mejor, amigo...|[mi mejor, mejor ...|        (2000,[],[])|        (2000,[],[])|(2025,[0,1,2,3,4,...|[-0.0927237791136...|[0.45377052360949...|       1.0|\n+--------+-------+--------+----------+--------------+----------+----------------+--------------------+--------------------+----------+---------+----------+-----+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+---------------+----------+---------------+--------------+-----------------+-------------------+--------------+-------------------+------------------+-------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":29},{"cell_type":"code","source":["#kaggle_pred.printSchema()"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":30},{"cell_type":"code","source":["kaggle_pred.groupBy(\"prediction\").count().show()"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+------+\nprediction| count|\n+----------+------+\n       0.0|289861|\n       1.0| 15123|\n+----------+------+\n\n</div>"]}}],"execution_count":31},{"cell_type":"code","source":["#display(kaggle_pred.select([\"reviewID\", \"prediction\"]))"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":32},{"cell_type":"code","source":["secondelement=udf(lambda v:float(v[1]),FloatType())\n#https://stackoverflow.com/questions/44425159/access-element-of-a-vector-in-a-spark-dataframe-logistic-regression-probability"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":33},{"cell_type":"code","source":["#kaggle_pred.select(secondelement('probability')).show(5)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":34},{"cell_type":"code","source":["display(kaggle_pred.select([\"reviewID\", secondelement('probability')]))"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>reviewID</th><th><lambda>(probability)</th></tr></thead><tbody><tr><td>67000000</td><td>0.21439695</td></tr><tr><td>67000001</td><td>0.37609625</td></tr><tr><td>67000002</td><td>0.16605978</td></tr><tr><td>67000003</td><td>0.2685534</td></tr><tr><td>67000004</td><td>0.5462295</td></tr><tr><td>67000005</td><td>0.17506598</td></tr><tr><td>67000006</td><td>0.29141527</td></tr><tr><td>67000007</td><td>0.37609625</td></tr><tr><td>67000008</td><td>0.8107678</td></tr><tr><td>67000009</td><td>0.37403417</td></tr><tr><td>67000010</td><td>0.04692401</td></tr><tr><td>67000011</td><td>0.119460925</td></tr><tr><td>67000012</td><td>0.039032917</td></tr><tr><td>67000013</td><td>0.1566363</td></tr><tr><td>67000014</td><td>0.05437039</td></tr><tr><td>67000015</td><td>0.044070788</td></tr><tr><td>67000016</td><td>0.17575881</td></tr><tr><td>67000017</td><td>0.049800232</td></tr><tr><td>67000018</td><td>0.076778494</td></tr><tr><td>67000019</td><td>0.30857286</td></tr><tr><td>67000020</td><td>0.07238744</td></tr><tr><td>67000021</td><td>0.04383007</td></tr><tr><td>67000022</td><td>0.1811885</td></tr><tr><td>67000023</td><td>0.030018857</td></tr><tr><td>67000024</td><td>0.31035906</td></tr><tr><td>67000025</td><td>0.108363114</td></tr><tr><td>67000026</td><td>0.094137475</td></tr><tr><td>67000027</td><td>0.16051842</td></tr><tr><td>67000028</td><td>0.5421162</td></tr><tr><td>67000029</td><td>0.1114301</td></tr><tr><td>67000030</td><td>0.03041549</td></tr><tr><td>67000031</td><td>0.19293012</td></tr><tr><td>67000032</td><td>0.21607436</td></tr><tr><td>67000033</td><td>0.21279825</td></tr><tr><td>67000034</td><td>0.07424098</td></tr><tr><td>67000035</td><td>0.16555217</td></tr><tr><td>67000036</td><td>0.20369981</td></tr><tr><td>67000037</td><td>0.031671688</td></tr><tr><td>67000038</td><td>0.18480042</td></tr><tr><td>67000039</td><td>0.6444191</td></tr><tr><td>67000040</td><td>0.20303197</td></tr><tr><td>67000041</td><td>0.23886281</td></tr><tr><td>67000042</td><td>0.044457603</td></tr><tr><td>67000043</td><td>0.074009016</td></tr><tr><td>67000044</td><td>0.24717002</td></tr><tr><td>67000045</td><td>0.13370158</td></tr><tr><td>67000046</td><td>0.07334289</td></tr><tr><td>67000047</td><td>0.56472254</td></tr><tr><td>67000048</td><td>0.42146793</td></tr><tr><td>67000049</td><td>0.09101592</td></tr><tr><td>67000050</td><td>0.061798323</td></tr><tr><td>67000051</td><td>0.43236136</td></tr><tr><td>67000052</td><td>0.21482721</td></tr><tr><td>67000053</td><td>0.28523389</td></tr><tr><td>67000054</td><td>0.04781608</td></tr><tr><td>67000055</td><td>0.029786758</td></tr><tr><td>67000056</td><td>0.1519308</td></tr><tr><td>67000057</td><td>0.2735172</td></tr><tr><td>67000058</td><td>0.092921294</td></tr><tr><td>67000059</td><td>0.5000151</td></tr><tr><td>67000060</td><td>0.14603296</td></tr><tr><td>67000061</td><td>0.680488</td></tr><tr><td>67000062</td><td>0.54798305</td></tr><tr><td>67000063</td><td>0.04438699</td></tr><tr><td>67000064</td><td>0.21374714</td></tr><tr><td>67000065</td><td>0.44606543</td></tr><tr><td>67000066</td><td>0.49316978</td></tr><tr><td>67000067</td><td>0.058592875</td></tr><tr><td>67000068</td><td>0.047689836</td></tr><tr><td>67000069</td><td>0.5315885</td></tr><tr><td>67000070</td><td>0.4985535</td></tr><tr><td>67000071</td><td>0.03104041</td></tr><tr><td>67000072</td><td>0.079813704</td></tr><tr><td>67000073</td><td>0.036992036</td></tr><tr><td>67000074</td><td>0.6771372</td></tr><tr><td>67000075</td><td>0.12553427</td></tr><tr><td>67000076</td><td>0.2036077</td></tr><tr><td>67000077</td><td>0.28579533</td></tr><tr><td>67000078</td><td>0.038540468</td></tr><tr><td>67000079</td><td>0.06047786</td></tr><tr><td>67000080</td><td>0.059491444</td></tr><tr><td>67000081</td><td>0.09576321</td></tr><tr><td>67000082</td><td>0.16877994</td></tr><tr><td>67000083</td><td>0.5369873</td></tr><tr><td>67000084</td><td>0.036643837</td></tr><tr><td>67000085</td><td>0.6425038</td></tr><tr><td>67000086</td><td>0.2492008</td></tr><tr><td>67000087</td><td>0.09545772</td></tr><tr><td>67000088</td><td>0.21907438</td></tr><tr><td>67000089</td><td>0.04744887</td></tr><tr><td>67000090</td><td>0.30075276</td></tr><tr><td>67000091</td><td>0.06365084</td></tr><tr><td>67000092</td><td>0.05220694</td></tr><tr><td>67000093</td><td>0.41336328</td></tr><tr><td>67000094</td><td>0.19722287</td></tr><tr><td>67000095</td><td>0.10370048</td></tr><tr><td>67000096</td><td>0.26541242</td></tr><tr><td>67000097</td><td>0.7454722</td></tr><tr><td>67000098</td><td>0.22492975</td></tr><tr><td>67000099</td><td>0.19480248</td></tr><tr><td>67000100</td><td>0.33112153</td></tr><tr><td>67000101</td><td>0.6222967</td></tr><tr><td>67000102</td><td>0.10764447</td></tr><tr><td>67000103</td><td>0.21010213</td></tr><tr><td>67000104</td><td>0.098238036</td></tr><tr><td>67000105</td><td>0.47175363</td></tr><tr><td>67000106</td><td>0.068747856</td></tr><tr><td>67000107</td><td>0.032030866</td></tr><tr><td>67000108</td><td>0.032847255</td></tr><tr><td>67000109</td><td>0.43394253</td></tr><tr><td>67000110</td><td>0.20703709</td></tr><tr><td>67000111</td><td>0.031671688</td></tr><tr><td>67000112</td><td>0.038699508</td></tr><tr><td>67000113</td><td>0.029407658</td></tr><tr><td>67000114</td><td>0.20615849</td></tr><tr><td>67000115</td><td>0.12098136</td></tr><tr><td>67000116</td><td>0.047776017</td></tr><tr><td>67000117</td><td>0.42414477</td></tr><tr><td>67000118</td><td>0.60159963</td></tr><tr><td>67000119</td><td>0.031824954</td></tr><tr><td>67000120</td><td>0.11332042</td></tr><tr><td>67000121</td><td>0.04645572</td></tr><tr><td>67000122</td><td>0.2756766</td></tr><tr><td>67000123</td><td>0.09129151</td></tr><tr><td>67000124</td><td>0.21279825</td></tr><tr><td>67000125</td><td>0.03909536</td></tr><tr><td>67000126</td><td>0.7759617</td></tr><tr><td>67000127</td><td>0.1566363</td></tr><tr><td>67000128</td><td>0.13060911</td></tr><tr><td>67000129</td><td>0.41664597</td></tr><tr><td>67000130</td><td>0.09288455</td></tr><tr><td>67000131</td><td>0.73504627</td></tr><tr><td>67000132</td><td>0.29638943</td></tr><tr><td>67000133</td><td>0.2553578</td></tr><tr><td>67000134</td><td>0.0426418</td></tr><tr><td>67000135</td><td>0.23014265</td></tr><tr><td>67000136</td><td>0.55346435</td></tr><tr><td>67000137</td><td>0.097590305</td></tr><tr><td>67000138</td><td>0.22585645</td></tr><tr><td>67000139</td><td>0.04574392</td></tr><tr><td>67000140</td><td>0.119186915</td></tr><tr><td>67000141</td><td>0.7281101</td></tr><tr><td>67000142</td><td>0.260986</td></tr><tr><td>67000143</td><td>0.07692542</td></tr><tr><td>67000144</td><td>0.23426776</td></tr><tr><td>67000145</td><td>0.197828</td></tr><tr><td>67000146</td><td>0.7391345</td></tr><tr><td>67000147</td><td>0.104557715</td></tr><tr><td>67000148</td><td>0.34651956</td></tr><tr><td>67000149</td><td>0.46971607</td></tr><tr><td>67000150</td><td>0.313855</td></tr><tr><td>67000151</td><td>0.7816883</td></tr><tr><td>67000152</td><td>0.03586345</td></tr><tr><td>67000153</td><td>0.75222224</td></tr><tr><td>67000154</td><td>0.052531302</td></tr><tr><td>67000155</td><td>0.46544874</td></tr><tr><td>67000156</td><td>0.36818627</td></tr><tr><td>67000157</td><td>0.1894515</td></tr><tr><td>67000158</td><td>0.2347189</td></tr><tr><td>67000159</td><td>0.05776541</td></tr><tr><td>67000160</td><td>0.05908162</td></tr><tr><td>67000161</td><td>0.21990123</td></tr><tr><td>67000162</td><td>0.07479782</td></tr><tr><td>67000163</td><td>0.07108159</td></tr><tr><td>67000164</td><td>0.5806105</td></tr><tr><td>67000165</td><td>0.029407658</td></tr><tr><td>67000166</td><td>0.036795348</td></tr><tr><td>67000167</td><td>0.029407658</td></tr><tr><td>67000168</td><td>0.2723368</td></tr><tr><td>67000169</td><td>0.42774397</td></tr><tr><td>67000170</td><td>0.035339843</td></tr><tr><td>67000171</td><td>0.050188094</td></tr><tr><td>67000172</td><td>0.16913942</td></tr><tr><td>67000173</td><td>0.031671688</td></tr><tr><td>67000174</td><td>0.7055329</td></tr><tr><td>67000175</td><td>0.038540468</td></tr><tr><td>67000176</td><td>0.061300863</td></tr><tr><td>67000177</td><td>0.038699508</td></tr><tr><td>67000178</td><td>0.49596593</td></tr><tr><td>67000179</td><td>0.22034556</td></tr><tr><td>67000180</td><td>0.16591717</td></tr><tr><td>67000181</td><td>0.09860795</td></tr><tr><td>67000182</td><td>0.15325339</td></tr><tr><td>67000183</td><td>0.1990903</td></tr><tr><td>67000184</td><td>0.031809572</td></tr><tr><td>67000185</td><td>0.411899</td></tr><tr><td>67000186</td><td>0.04645572</td></tr><tr><td>67000187</td><td>0.057938587</td></tr><tr><td>67000188</td><td>0.43127224</td></tr><tr><td>67000189</td><td>0.047660243</td></tr><tr><td>67000190</td><td>0.42010897</td></tr><tr><td>67000191</td><td>0.19376345</td></tr><tr><td>67000192</td><td>0.2870811</td></tr><tr><td>67000193</td><td>0.0567518</td></tr><tr><td>67000194</td><td>0.39119554</td></tr><tr><td>67000195</td><td>0.05966639</td></tr><tr><td>67000196</td><td>0.120513104</td></tr><tr><td>67000197</td><td>0.17001796</td></tr><tr><td>67000198</td><td>0.74625725</td></tr><tr><td>67000199</td><td>0.16468012</td></tr><tr><td>67000200</td><td>0.29211274</td></tr><tr><td>67000201</td><td>0.7317358</td></tr><tr><td>67000202</td><td>0.1587912</td></tr><tr><td>67000203</td><td>0.051447306</td></tr><tr><td>67000204</td><td>0.6741667</td></tr><tr><td>67000205</td><td>0.0707396</td></tr><tr><td>67000206</td><td>0.4156373</td></tr><tr><td>67000207</td><td>0.2105485</td></tr><tr><td>67000208</td><td>0.04400994</td></tr><tr><td>67000209</td><td>0.25418234</td></tr><tr><td>67000210</td><td>0.1964308</td></tr><tr><td>67000211</td><td>0.04400994</td></tr><tr><td>67000212</td><td>0.056164224</td></tr><tr><td>67000213</td><td>0.16692004</td></tr><tr><td>67000214</td><td>0.35601166</td></tr><tr><td>67000215</td><td>0.08327382</td></tr><tr><td>67000216</td><td>0.17744303</td></tr><tr><td>67000217</td><td>0.1500066</td></tr><tr><td>67000218</td><td>0.7123055</td></tr><tr><td>67000219</td><td>0.08677771</td></tr><tr><td>67000220</td><td>0.04638083</td></tr><tr><td>67000221</td><td>0.41853443</td></tr><tr><td>67000222</td><td>0.20773974</td></tr><tr><td>67000223</td><td>0.03481837</td></tr><tr><td>67000224</td><td>0.14553641</td></tr><tr><td>67000225</td><td>0.2176811</td></tr><tr><td>67000226</td><td>0.14086187</td></tr><tr><td>67000227</td><td>0.24778202</td></tr><tr><td>67000228</td><td>0.07813059</td></tr><tr><td>67000229</td><td>0.19433118</td></tr><tr><td>67000230</td><td>0.18992254</td></tr><tr><td>67000231</td><td>0.04598717</td></tr><tr><td>67000232</td><td>0.27617335</td></tr><tr><td>67000233</td><td>0.06472498</td></tr><tr><td>67000234</td><td>0.07627523</td></tr><tr><td>67000235</td><td>0.18339804</td></tr><tr><td>67000236</td><td>0.11579625</td></tr><tr><td>67000237</td><td>0.24646084</td></tr><tr><td>67000238</td><td>0.051447306</td></tr><tr><td>67000239</td><td>0.46971607</td></tr><tr><td>67000240</td><td>0.192405</td></tr><tr><td>67000241</td><td>0.07104237</td></tr><tr><td>67000242</td><td>0.46330324</td></tr><tr><td>67000243</td><td>0.29141527</td></tr><tr><td>67000244</td><td>0.111781344</td></tr><tr><td>67000245</td><td>0.21322615</td></tr><tr><td>67000246</td><td>0.09364949</td></tr><tr><td>67000247</td><td>0.19383436</td></tr><tr><td>67000248</td><td>0.05220694</td></tr><tr><td>67000249</td><td>0.07581969</td></tr><tr><td>67000250</td><td>0.18713419</td></tr><tr><td>67000251</td><td>0.16238672</td></tr><tr><td>67000252</td><td>0.03696961</td></tr><tr><td>67000253</td><td>0.2592625</td></tr><tr><td>67000254</td><td>0.0677951</td></tr><tr><td>67000255</td><td>0.4448992</td></tr><tr><td>67000256</td><td>0.04227892</td></tr><tr><td>67000257</td><td>0.03203847</td></tr><tr><td>67000258</td><td>0.48931518</td></tr><tr><td>67000259</td><td>0.0802849</td></tr><tr><td>67000260</td><td>0.05517241</td></tr><tr><td>67000261</td><td>0.04438699</td></tr><tr><td>67000262</td><td>0.15282346</td></tr><tr><td>67000263</td><td>0.5951435</td></tr><tr><td>67000264</td><td>0.6366941</td></tr><tr><td>67000265</td><td>0.17547864</td></tr><tr><td>67000266</td><td>0.038934764</td></tr><tr><td>67000267</td><td>0.1610794</td></tr><tr><td>67000268</td><td>0.03909536</td></tr><tr><td>67000269</td><td>0.072209835</td></tr><tr><td>67000270</td><td>0.60139567</td></tr><tr><td>67000271</td><td>0.27891624</td></tr><tr><td>67000272</td><td>0.17575881</td></tr><tr><td>67000273</td><td>0.030300576</td></tr><tr><td>67000274</td><td>0.13018297</td></tr><tr><td>67000275</td><td>0.04492164</td></tr><tr><td>67000276</td><td>0.20475547</td></tr><tr><td>67000277</td><td>0.1137048</td></tr><tr><td>67000278</td><td>0.049800232</td></tr><tr><td>67000279</td><td>0.2776854</td></tr><tr><td>67000280</td><td>0.46799055</td></tr><tr><td>67000281</td><td>0.079168424</td></tr><tr><td>67000282</td><td>0.06606931</td></tr><tr><td>67000283</td><td>0.5942728</td></tr><tr><td>67000284</td><td>0.25496244</td></tr><tr><td>67000285</td><td>0.22255677</td></tr><tr><td>67000286</td><td>0.3827893</td></tr><tr><td>67000287</td><td>0.24717002</td></tr><tr><td>67000288</td><td>0.03723532</td></tr><tr><td>67000289</td><td>0.14299834</td></tr><tr><td>67000290</td><td>0.050160762</td></tr><tr><td>67000291</td><td>0.12061393</td></tr><tr><td>67000292</td><td>0.051266897</td></tr><tr><td>67000293</td><td>0.12438169</td></tr><tr><td>67000294</td><td>0.06047786</td></tr><tr><td>67000295</td><td>0.15067673</td></tr><tr><td>67000296</td><td>0.1192293</td></tr><tr><td>67000297</td><td>0.42842457</td></tr><tr><td>67000298</td><td>0.20018892</td></tr><tr><td>67000299</td><td>0.40652606</td></tr><tr><td>67000300</td><td>0.16927442</td></tr><tr><td>67000301</td><td>0.14188133</td></tr><tr><td>67000302</td><td>0.029407658</td></tr><tr><td>67000303</td><td>0.13508259</td></tr><tr><td>67000304</td><td>0.036163986</td></tr><tr><td>67000305</td><td>0.11824751</td></tr><tr><td>67000306</td><td>0.2595498</td></tr><tr><td>67000307</td><td>0.038540468</td></tr><tr><td>67000308</td><td>0.5525771</td></tr><tr><td>67000309</td><td>0.04438699</td></tr><tr><td>67000310</td><td>0.1845614</td></tr><tr><td>67000311</td><td>0.18644299</td></tr><tr><td>67000312</td><td>0.3336503</td></tr><tr><td>67000313</td><td>0.046569712</td></tr><tr><td>67000314</td><td>0.26947442</td></tr><tr><td>67000315</td><td>0.57976294</td></tr><tr><td>67000316</td><td>0.5930351</td></tr><tr><td>67000317</td><td>0.031671688</td></tr><tr><td>67000318</td><td>0.21777987</td></tr><tr><td>67000319</td><td>0.04400994</td></tr><tr><td>67000320</td><td>0.12691446</td></tr><tr><td>67000321</td><td>0.6055661</td></tr><tr><td>67000322</td><td>0.4725153</td></tr><tr><td>67000323</td><td>0.07158875</td></tr><tr><td>67000324</td><td>0.7382869</td></tr><tr><td>67000325</td><td>0.22980279</td></tr><tr><td>67000326</td><td>0.13921234</td></tr><tr><td>67000327</td><td>0.35727534</td></tr><tr><td>67000328</td><td>0.07441848</td></tr><tr><td>67000329</td><td>0.037400175</td></tr><tr><td>67000330</td><td>0.33307248</td></tr><tr><td>67000331</td><td>0.50620127</td></tr><tr><td>67000332</td><td>0.034653883</td></tr><tr><td>67000333</td><td>0.029573461</td></tr><tr><td>67000334</td><td>0.07390383</td></tr><tr><td>67000335</td><td>0.7542863</td></tr><tr><td>67000336</td><td>0.05512809</td></tr><tr><td>67000337</td><td>0.12337585</td></tr><tr><td>67000338</td><td>0.07091512</td></tr><tr><td>67000339</td><td>0.04577971</td></tr><tr><td>67000340</td><td>0.25822</td></tr><tr><td>67000341</td><td>0.031824954</td></tr><tr><td>67000342</td><td>0.14188133</td></tr><tr><td>67000343</td><td>0.24027519</td></tr><tr><td>67000344</td><td>0.058486555</td></tr><tr><td>67000345</td><td>0.05731764</td></tr><tr><td>67000346</td><td>0.5185365</td></tr><tr><td>67000347</td><td>0.07033303</td></tr><tr><td>67000348</td><td>0.07982789</td></tr><tr><td>67000349</td><td>0.6222967</td></tr><tr><td>67000350</td><td>0.26914978</td></tr><tr><td>67000351</td><td>0.15566309</td></tr><tr><td>67000352</td><td>0.07418272</td></tr><tr><td>67000353</td><td>0.07837815</td></tr><tr><td>67000354</td><td>0.25256297</td></tr><tr><td>67000355</td><td>0.07783582</td></tr><tr><td>67000356</td><td>0.36566237</td></tr><tr><td>67000357</td><td>0.537081</td></tr><tr><td>67000358</td><td>0.54830325</td></tr><tr><td>67000359</td><td>0.111279406</td></tr><tr><td>67000360</td><td>0.49874687</td></tr><tr><td>67000361</td><td>0.23269583</td></tr><tr><td>67000362</td><td>0.047839623</td></tr><tr><td>67000363</td><td>0.03628532</td></tr><tr><td>67000364</td><td>0.029407658</td></tr><tr><td>67000365</td><td>0.08326193</td></tr><tr><td>67000366</td><td>0.7185843</td></tr><tr><td>67000367</td><td>0.1927449</td></tr><tr><td>67000368</td><td>0.09962442</td></tr><tr><td>67000369</td><td>0.1802078</td></tr><tr><td>67000370</td><td>0.15560097</td></tr><tr><td>67000371</td><td>0.42116597</td></tr><tr><td>67000372</td><td>0.029407658</td></tr><tr><td>67000373</td><td>0.04400994</td></tr><tr><td>67000374</td><td>0.06047786</td></tr><tr><td>67000375</td><td>0.066370435</td></tr><tr><td>67000376</td><td>0.34765333</td></tr><tr><td>67000377</td><td>0.585306</td></tr><tr><td>67000378</td><td>0.08636974</td></tr><tr><td>67000379</td><td>0.4845928</td></tr><tr><td>67000380</td><td>0.7484873</td></tr><tr><td>67000381</td><td>0.029407658</td></tr><tr><td>67000382</td><td>0.04400994</td></tr><tr><td>67000383</td><td>0.13652624</td></tr><tr><td>67000384</td><td>0.03201785</td></tr><tr><td>67000385</td><td>0.26526022</td></tr><tr><td>67000386</td><td>0.202369</td></tr><tr><td>67000387</td><td>0.051983442</td></tr><tr><td>67000388</td><td>0.056502644</td></tr><tr><td>67000389</td><td>0.23822464</td></tr><tr><td>67000390</td><td>0.20196141</td></tr><tr><td>67000391</td><td>0.46330324</td></tr><tr><td>67000392</td><td>0.40727937</td></tr><tr><td>67000393</td><td>0.051128156</td></tr><tr><td>67000394</td><td>0.045704033</td></tr><tr><td>67000395</td><td>0.08619892</td></tr><tr><td>67000396</td><td>0.091966994</td></tr><tr><td>67000397</td><td>0.24295712</td></tr><tr><td>67000398</td><td>0.08161401</td></tr><tr><td>67000399</td><td>0.80742764</td></tr><tr><td>67000400</td><td>0.030513875</td></tr><tr><td>67000401</td><td>0.3945866</td></tr><tr><td>67000402</td><td>0.029495033</td></tr><tr><td>67000403</td><td>0.33810142</td></tr><tr><td>67000404</td><td>0.11970443</td></tr><tr><td>67000405</td><td>0.3299131</td></tr><tr><td>67000406</td><td>0.09270773</td></tr><tr><td>67000407</td><td>0.094696224</td></tr><tr><td>67000408</td><td>0.054939702</td></tr><tr><td>67000409</td><td>0.18183084</td></tr><tr><td>67000410</td><td>0.7089808</td></tr><tr><td>67000411</td><td>0.04645572</td></tr><tr><td>67000412</td><td>0.119186915</td></tr><tr><td>67000413</td><td>0.062787995</td></tr><tr><td>67000414</td><td>0.19882579</td></tr><tr><td>67000415</td><td>0.060691457</td></tr><tr><td>67000416</td><td>0.10606585</td></tr><tr><td>67000417</td><td>0.70518255</td></tr><tr><td>67000418</td><td>0.08721597</td></tr><tr><td>67000419</td><td>0.6368327</td></tr><tr><td>67000420</td><td>0.27608597</td></tr><tr><td>67000421</td><td>0.14303255</td></tr><tr><td>67000422</td><td>0.09163516</td></tr><tr><td>67000423</td><td>0.4032838</td></tr><tr><td>67000424</td><td>0.8088898</td></tr><tr><td>67000425</td><td>0.16030389</td></tr><tr><td>67000426</td><td>0.05144568</td></tr><tr><td>67000427</td><td>0.032705024</td></tr><tr><td>67000428</td><td>0.27959177</td></tr><tr><td>67000429</td><td>0.18261513</td></tr><tr><td>67000430</td><td>0.06491058</td></tr><tr><td>67000431</td><td>0.1987663</td></tr><tr><td>67000432</td><td>0.72064775</td></tr><tr><td>67000433</td><td>0.12623626</td></tr><tr><td>67000434</td><td>0.22937483</td></tr><tr><td>67000435</td><td>0.06506572</td></tr><tr><td>67000436</td><td>0.26494792</td></tr><tr><td>67000437</td><td>0.29097888</td></tr><tr><td>67000438</td><td>0.36310366</td></tr><tr><td>67000439</td><td>0.06580793</td></tr><tr><td>67000440</td><td>0.04861718</td></tr><tr><td>67000441</td><td>0.37609625</td></tr><tr><td>67000442</td><td>0.4404642</td></tr><tr><td>67000443</td><td>0.5226831</td></tr><tr><td>67000444</td><td>0.77616775</td></tr><tr><td>67000445</td><td>0.09710109</td></tr><tr><td>67000446</td><td>0.13853627</td></tr><tr><td>67000447</td><td>0.21507578</td></tr><tr><td>67000448</td><td>0.20409927</td></tr><tr><td>67000449</td><td>0.20451553</td></tr><tr><td>67000450</td><td>0.14311145</td></tr><tr><td>67000451</td><td>0.07034671</td></tr><tr><td>67000452</td><td>0.2776854</td></tr><tr><td>67000453</td><td>0.44716662</td></tr><tr><td>67000454</td><td>0.39398542</td></tr><tr><td>67000455</td><td>0.31078443</td></tr><tr><td>67000456</td><td>0.48490062</td></tr><tr><td>67000457</td><td>0.26492274</td></tr><tr><td>67000458</td><td>0.73077714</td></tr><tr><td>67000459</td><td>0.22570904</td></tr><tr><td>67000460</td><td>0.34918848</td></tr><tr><td>67000461</td><td>0.7134177</td></tr><tr><td>67000462</td><td>0.7762911</td></tr><tr><td>67000463</td><td>0.28009465</td></tr><tr><td>67000464</td><td>0.09860795</td></tr><tr><td>67000465</td><td>0.32710242</td></tr><tr><td>67000466</td><td>0.065067776</td></tr><tr><td>67000467</td><td>0.111221015</td></tr><tr><td>67000468</td><td>0.12994473</td></tr><tr><td>67000469</td><td>0.4151899</td></tr><tr><td>67000470</td><td>0.059631485</td></tr><tr><td>67000471</td><td>0.17735232</td></tr><tr><td>67000472</td><td>0.029407658</td></tr><tr><td>67000473</td><td>0.062925585</td></tr><tr><td>67000474</td><td>0.08327471</td></tr><tr><td>67000475</td><td>0.27617335</td></tr><tr><td>67000476</td><td>0.038699508</td></tr><tr><td>67000477</td><td>0.7080809</td></tr><tr><td>67000478</td><td>0.27959847</td></tr><tr><td>67000479</td><td>0.03909536</td></tr><tr><td>67000480</td><td>0.033432517</td></tr><tr><td>67000481</td><td>0.33307248</td></tr><tr><td>67000482</td><td>0.08133059</td></tr><tr><td>67000483</td><td>0.072950214</td></tr><tr><td>67000484</td><td>0.10788844</td></tr><tr><td>67000485</td><td>0.059972554</td></tr><tr><td>67000486</td><td>0.448711</td></tr><tr><td>67000487</td><td>0.43006712</td></tr><tr><td>67000488</td><td>0.06966876</td></tr><tr><td>67000489</td><td>0.099911116</td></tr><tr><td>67000490</td><td>0.029407658</td></tr><tr><td>67000491</td><td>0.029986674</td></tr><tr><td>67000492</td><td>0.15509367</td></tr><tr><td>67000493</td><td>0.029407658</td></tr><tr><td>67000494</td><td>0.77714944</td></tr><tr><td>67000495</td><td>0.053631548</td></tr><tr><td>67000496</td><td>0.11614796</td></tr><tr><td>67000497</td><td>0.26458395</td></tr><tr><td>67000498</td><td>0.07972186</td></tr><tr><td>67000499</td><td>0.18094239</td></tr><tr><td>67000500</td><td>0.19666886</td></tr><tr><td>67000501</td><td>0.7129741</td></tr><tr><td>67000502</td><td>0.19894281</td></tr><tr><td>67000503</td><td>0.22434701</td></tr><tr><td>67000504</td><td>0.2032069</td></tr><tr><td>67000505</td><td>0.07190812</td></tr><tr><td>67000506</td><td>0.044457603</td></tr><tr><td>67000507</td><td>0.7617312</td></tr><tr><td>67000508</td><td>0.030197829</td></tr><tr><td>67000509</td><td>0.12044356</td></tr><tr><td>67000510</td><td>0.13385755</td></tr><tr><td>67000511</td><td>0.21268715</td></tr><tr><td>67000512</td><td>0.27903053</td></tr><tr><td>67000513</td><td>0.17547864</td></tr><tr><td>67000514</td><td>0.43006712</td></tr><tr><td>67000515</td><td>0.39605063</td></tr><tr><td>67000516</td><td>0.036992036</td></tr><tr><td>67000517</td><td>0.23870143</td></tr><tr><td>67000518</td><td>0.12955247</td></tr><tr><td>67000519</td><td>0.029619798</td></tr><tr><td>67000520</td><td>0.051966634</td></tr><tr><td>67000521</td><td>0.029407658</td></tr><tr><td>67000522</td><td>0.2569004</td></tr><tr><td>67000523</td><td>0.14188133</td></tr><tr><td>67000524</td><td>0.2081838</td></tr><tr><td>67000525</td><td>0.12139702</td></tr><tr><td>67000526</td><td>0.037636943</td></tr><tr><td>67000527</td><td>0.16973437</td></tr><tr><td>67000528</td><td>0.0698946</td></tr><tr><td>67000529</td><td>0.5805601</td></tr><tr><td>67000530</td><td>0.034231395</td></tr><tr><td>67000531</td><td>0.06893184</td></tr><tr><td>67000532</td><td>0.25928834</td></tr><tr><td>67000533</td><td>0.070652016</td></tr><tr><td>67000534</td><td>0.029407658</td></tr><tr><td>67000535</td><td>0.14820112</td></tr><tr><td>67000536</td><td>0.30834287</td></tr><tr><td>67000537</td><td>0.05966639</td></tr><tr><td>67000538</td><td>0.08962726</td></tr><tr><td>67000539</td><td>0.12467024</td></tr><tr><td>67000540</td><td>0.121695645</td></tr><tr><td>67000541</td><td>0.10243916</td></tr><tr><td>67000542</td><td>0.05908162</td></tr><tr><td>67000543</td><td>0.10020553</td></tr><tr><td>67000544</td><td>0.037489977</td></tr><tr><td>67000545</td><td>0.09630059</td></tr><tr><td>67000546</td><td>0.20745125</td></tr><tr><td>67000547</td><td>0.34050786</td></tr><tr><td>67000548</td><td>0.62581694</td></tr><tr><td>67000549</td><td>0.51528776</td></tr><tr><td>67000550</td><td>0.27959847</td></tr><tr><td>67000551</td><td>0.21196839</td></tr><tr><td>67000552</td><td>0.05775029</td></tr><tr><td>67000553</td><td>0.0461425</td></tr><tr><td>67000554</td><td>0.117944896</td></tr><tr><td>67000555</td><td>0.038699508</td></tr><tr><td>67000556</td><td>0.12064795</td></tr><tr><td>67000557</td><td>0.17636237</td></tr><tr><td>67000558</td><td>0.03909536</td></tr><tr><td>67000559</td><td>0.1531124</td></tr><tr><td>67000560</td><td>0.0773907</td></tr><tr><td>67000561</td><td>0.5656</td></tr><tr><td>67000562</td><td>0.05293259</td></tr><tr><td>67000563</td><td>0.2664897</td></tr><tr><td>67000564</td><td>0.05812013</td></tr><tr><td>67000565</td><td>0.30258787</td></tr><tr><td>67000566</td><td>0.047050826</td></tr><tr><td>67000567</td><td>0.41999304</td></tr><tr><td>67000568</td><td>0.19731401</td></tr><tr><td>67000569</td><td>0.15243368</td></tr><tr><td>67000570</td><td>0.07334289</td></tr><tr><td>67000571</td><td>0.07123352</td></tr><tr><td>67000572</td><td>0.19792281</td></tr><tr><td>67000573</td><td>0.37609625</td></tr><tr><td>67000574</td><td>0.14898194</td></tr><tr><td>67000575</td><td>0.057318106</td></tr><tr><td>67000576</td><td>0.12828021</td></tr><tr><td>67000577</td><td>0.082371935</td></tr><tr><td>67000578</td><td>0.22492975</td></tr><tr><td>67000579</td><td>0.14299834</td></tr><tr><td>67000580</td><td>0.20349978</td></tr><tr><td>67000581</td><td>0.449278</td></tr><tr><td>67000582</td><td>0.5962586</td></tr><tr><td>67000583</td><td>0.23420134</td></tr><tr><td>67000584</td><td>0.44179174</td></tr><tr><td>67000585</td><td>0.038699508</td></tr><tr><td>67000586</td><td>0.17343824</td></tr><tr><td>67000587</td><td>0.03224819</td></tr><tr><td>67000588</td><td>0.26334655</td></tr><tr><td>67000589</td><td>0.031671688</td></tr><tr><td>67000590</td><td>0.1260296</td></tr><tr><td>67000591</td><td>0.44175646</td></tr><tr><td>67000592</td><td>0.2760987</td></tr><tr><td>67000593</td><td>0.049800232</td></tr><tr><td>67000594</td><td>0.030300576</td></tr><tr><td>67000595</td><td>0.29658788</td></tr><tr><td>67000596</td><td>0.06047786</td></tr><tr><td>67000597</td><td>0.04483831</td></tr><tr><td>67000598</td><td>0.73617023</td></tr><tr><td>67000599</td><td>0.07592404</td></tr><tr><td>67000600</td><td>0.04635547</td></tr><tr><td>67000601</td><td>0.07597131</td></tr><tr><td>67000602</td><td>0.32092872</td></tr><tr><td>67000603</td><td>0.096263364</td></tr><tr><td>67000604</td><td>0.096773386</td></tr><tr><td>67000605</td><td>0.15509367</td></tr><tr><td>67000606</td><td>0.13120097</td></tr><tr><td>67000607</td><td>0.6627027</td></tr><tr><td>67000608</td><td>0.045440923</td></tr><tr><td>67000609</td><td>0.23940882</td></tr><tr><td>67000610</td><td>0.18644299</td></tr><tr><td>67000611</td><td>0.48788792</td></tr><tr><td>67000612</td><td>0.035119567</td></tr><tr><td>67000613</td><td>0.1995544</td></tr><tr><td>67000614</td><td>0.099336036</td></tr><tr><td>67000615</td><td>0.67875934</td></tr><tr><td>67000616</td><td>0.30431587</td></tr><tr><td>67000617</td><td>0.03559031</td></tr><tr><td>67000618</td><td>0.13458328</td></tr><tr><td>67000619</td><td>0.23471089</td></tr><tr><td>67000620</td><td>0.12139702</td></tr><tr><td>67000621</td><td>0.12064795</td></tr><tr><td>67000622</td><td>0.05109864</td></tr><tr><td>67000623</td><td>0.0327631</td></tr><tr><td>67000624</td><td>0.050160762</td></tr><tr><td>67000625</td><td>0.12222739</td></tr><tr><td>67000626</td><td>0.66761124</td></tr><tr><td>67000627</td><td>0.04501014</td></tr><tr><td>67000628</td><td>0.22460897</td></tr><tr><td>67000629</td><td>0.57480145</td></tr><tr><td>67000630</td><td>0.20757532</td></tr><tr><td>67000631</td><td>0.15952745</td></tr><tr><td>67000632</td><td>0.45473468</td></tr><tr><td>67000633</td><td>0.3353401</td></tr><tr><td>67000634</td><td>0.029986674</td></tr><tr><td>67000635</td><td>0.087849304</td></tr><tr><td>67000636</td><td>0.087436706</td></tr><tr><td>67000637</td><td>0.10622407</td></tr><tr><td>67000638</td><td>0.61862284</td></tr><tr><td>67000639</td><td>0.52372056</td></tr><tr><td>67000640</td><td>0.0939279</td></tr><tr><td>67000641</td><td>0.2735172</td></tr><tr><td>67000642</td><td>0.09738426</td></tr><tr><td>67000643</td><td>0.2536646</td></tr><tr><td>67000644</td><td>0.03338313</td></tr><tr><td>67000645</td><td>0.055062763</td></tr><tr><td>67000646</td><td>0.09320284</td></tr><tr><td>67000647</td><td>0.21367292</td></tr><tr><td>67000648</td><td>0.05205668</td></tr><tr><td>67000649</td><td>0.6195779</td></tr><tr><td>67000650</td><td>0.12848294</td></tr><tr><td>67000651</td><td>0.1716402</td></tr><tr><td>67000652</td><td>0.20206872</td></tr><tr><td>67000653</td><td>0.20961355</td></tr><tr><td>67000654</td><td>0.44722992</td></tr><tr><td>67000655</td><td>0.5628125</td></tr><tr><td>67000656</td><td>0.1627367</td></tr><tr><td>67000657</td><td>0.21120824</td></tr><tr><td>67000658</td><td>0.30300108</td></tr><tr><td>67000659</td><td>0.10370048</td></tr><tr><td>67000660</td><td>0.029407658</td></tr><tr><td>67000661</td><td>0.12298771</td></tr><tr><td>67000662</td><td>0.25642923</td></tr><tr><td>67000663</td><td>0.037704807</td></tr><tr><td>67000664</td><td>0.12402206</td></tr><tr><td>67000665</td><td>0.07864686</td></tr><tr><td>67000666</td><td>0.044728175</td></tr><tr><td>67000667</td><td>0.6577731</td></tr><tr><td>67000668</td><td>0.048444066</td></tr><tr><td>67000669</td><td>0.06469929</td></tr><tr><td>67000670</td><td>0.20594032</td></tr><tr><td>67000671</td><td>0.14415999</td></tr><tr><td>67000672</td><td>0.6225783</td></tr><tr><td>67000673</td><td>0.31187928</td></tr><tr><td>67000674</td><td>0.04096364</td></tr><tr><td>67000675</td><td>0.062683955</td></tr><tr><td>67000676</td><td>0.105824485</td></tr><tr><td>67000677</td><td>0.27432007</td></tr><tr><td>67000678</td><td>0.09516573</td></tr><tr><td>67000679</td><td>0.3647483</td></tr><tr><td>67000680</td><td>0.057526056</td></tr><tr><td>67000681</td><td>0.063900776</td></tr><tr><td>67000682</td><td>0.23295812</td></tr><tr><td>67000683</td><td>0.71946293</td></tr><tr><td>67000684</td><td>0.16295442</td></tr><tr><td>67000685</td><td>0.4587392</td></tr><tr><td>67000686</td><td>0.45263827</td></tr><tr><td>67000687</td><td>0.7565979</td></tr><tr><td>67000688</td><td>0.36556736</td></tr><tr><td>67000689</td><td>0.062017046</td></tr><tr><td>67000690</td><td>0.10406222</td></tr><tr><td>67000691</td><td>0.03203847</td></tr><tr><td>67000692</td><td>0.16633563</td></tr><tr><td>67000693</td><td>0.06247946</td></tr><tr><td>67000694</td><td>0.04645572</td></tr><tr><td>67000695</td><td>0.37386557</td></tr><tr><td>67000696</td><td>0.054848365</td></tr><tr><td>67000697</td><td>0.038699508</td></tr><tr><td>67000698</td><td>0.058486555</td></tr><tr><td>67000699</td><td>0.3060221</td></tr><tr><td>67000700</td><td>0.07238744</td></tr><tr><td>67000701</td><td>0.67261076</td></tr><tr><td>67000702</td><td>0.14311145</td></tr><tr><td>67000703</td><td>0.038699508</td></tr><tr><td>67000704</td><td>0.22117604</td></tr><tr><td>67000705</td><td>0.029407658</td></tr><tr><td>67000706</td><td>0.36546025</td></tr><tr><td>67000707</td><td>0.12721965</td></tr><tr><td>67000708</td><td>0.1242696</td></tr><tr><td>67000709</td><td>0.291201</td></tr><tr><td>67000710</td><td>0.031671688</td></tr><tr><td>67000711</td><td>0.04400994</td></tr><tr><td>67000712</td><td>0.059491444</td></tr><tr><td>67000713</td><td>0.14325635</td></tr><tr><td>67000714</td><td>0.26547205</td></tr><tr><td>67000715</td><td>0.4116177</td></tr><tr><td>67000716</td><td>0.450512</td></tr><tr><td>67000717</td><td>0.41650635</td></tr><tr><td>67000718</td><td>0.034191288</td></tr><tr><td>67000719</td><td>0.07819304</td></tr><tr><td>67000720</td><td>0.16321284</td></tr><tr><td>67000721</td><td>0.77866524</td></tr><tr><td>67000722</td><td>0.6511554</td></tr><tr><td>67000723</td><td>0.040769883</td></tr><tr><td>67000724</td><td>0.16228628</td></tr><tr><td>67000725</td><td>0.27959847</td></tr><tr><td>67000726</td><td>0.49022368</td></tr><tr><td>67000727</td><td>0.07091138</td></tr><tr><td>67000728</td><td>0.03398313</td></tr><tr><td>67000729</td><td>0.49282682</td></tr><tr><td>67000730</td><td>0.20887735</td></tr><tr><td>67000731</td><td>0.048321158</td></tr><tr><td>67000732</td><td>0.14021212</td></tr><tr><td>67000733</td><td>0.21138656</td></tr><tr><td>67000734</td><td>0.029619798</td></tr><tr><td>67000735</td><td>0.3311881</td></tr><tr><td>67000736</td><td>0.0567518</td></tr><tr><td>67000737</td><td>0.04711584</td></tr><tr><td>67000738</td><td>0.5953235</td></tr><tr><td>67000739</td><td>0.3386267</td></tr><tr><td>67000740</td><td>0.11900841</td></tr><tr><td>67000741</td><td>0.29125196</td></tr><tr><td>67000742</td><td>0.23346072</td></tr><tr><td>67000743</td><td>0.06158719</td></tr><tr><td>67000744</td><td>0.04096364</td></tr><tr><td>67000745</td><td>0.049800232</td></tr><tr><td>67000746</td><td>0.28904033</td></tr><tr><td>67000747</td><td>0.2995286</td></tr><tr><td>67000748</td><td>0.06510999</td></tr><tr><td>67000749</td><td>0.038699508</td></tr><tr><td>67000750</td><td>0.15831232</td></tr><tr><td>67000751</td><td>0.13525437</td></tr><tr><td>67000752</td><td>0.029619798</td></tr><tr><td>67000753</td><td>0.07570928</td></tr><tr><td>67000754</td><td>0.12356079</td></tr><tr><td>67000755</td><td>0.17174828</td></tr><tr><td>67000756</td><td>0.069801114</td></tr><tr><td>67000757</td><td>0.074223734</td></tr><tr><td>67000758</td><td>0.2461832</td></tr><tr><td>67000759</td><td>0.032177698</td></tr><tr><td>67000760</td><td>0.79271203</td></tr><tr><td>67000761</td><td>0.8150931</td></tr><tr><td>67000762</td><td>0.26792678</td></tr><tr><td>67000763</td><td>0.07034671</td></tr><tr><td>67000764</td><td>0.53756934</td></tr><tr><td>67000765</td><td>0.06661443</td></tr><tr><td>67000766</td><td>0.07595704</td></tr><tr><td>67000767</td><td>0.069595225</td></tr><tr><td>67000768</td><td>0.42489955</td></tr><tr><td>67000769</td><td>0.1335404</td></tr><tr><td>67000770</td><td>0.68864816</td></tr><tr><td>67000771</td><td>0.17768694</td></tr><tr><td>67000772</td><td>0.101049826</td></tr><tr><td>67000773</td><td>0.23718642</td></tr><tr><td>67000774</td><td>0.03909536</td></tr><tr><td>67000775</td><td>0.091165125</td></tr><tr><td>67000776</td><td>0.20706418</td></tr><tr><td>67000777</td><td>0.7011648</td></tr><tr><td>67000778</td><td>0.20265533</td></tr><tr><td>67000779</td><td>0.5052058</td></tr><tr><td>67000780</td><td>0.03909536</td></tr><tr><td>67000781</td><td>0.051447306</td></tr><tr><td>67000782</td><td>0.23940882</td></tr><tr><td>67000783</td><td>0.08730474</td></tr><tr><td>67000784</td><td>0.07840898</td></tr><tr><td>67000785</td><td>0.03151384</td></tr><tr><td>67000786</td><td>0.22570904</td></tr><tr><td>67000787</td><td>0.09639704</td></tr><tr><td>67000788</td><td>0.22923753</td></tr><tr><td>67000789</td><td>0.18967174</td></tr><tr><td>67000790</td><td>0.05194899</td></tr><tr><td>67000791</td><td>0.038357716</td></tr><tr><td>67000792</td><td>0.072415665</td></tr><tr><td>67000793</td><td>0.4356679</td></tr><tr><td>67000794</td><td>0.052736424</td></tr><tr><td>67000795</td><td>0.101049826</td></tr><tr><td>67000796</td><td>0.31611404</td></tr><tr><td>67000797</td><td>0.78276116</td></tr><tr><td>67000798</td><td>0.029407658</td></tr><tr><td>67000799</td><td>0.42414477</td></tr><tr><td>67000800</td><td>0.029407658</td></tr><tr><td>67000801</td><td>0.17124249</td></tr><tr><td>67000802</td><td>0.030197829</td></tr><tr><td>67000803</td><td>0.09158718</td></tr><tr><td>67000804</td><td>0.04383007</td></tr><tr><td>67000805</td><td>0.44140422</td></tr><tr><td>67000806</td><td>0.5501843</td></tr><tr><td>67000807</td><td>0.10624772</td></tr><tr><td>67000808</td><td>0.12079692</td></tr><tr><td>67000809</td><td>0.054675207</td></tr><tr><td>67000810</td><td>0.34226617</td></tr><tr><td>67000811</td><td>0.25913805</td></tr><tr><td>67000812</td><td>0.1423218</td></tr><tr><td>67000813</td><td>0.11964183</td></tr><tr><td>67000814</td><td>0.42916983</td></tr><tr><td>67000815</td><td>0.20734623</td></tr><tr><td>67000816</td><td>0.6126998</td></tr><tr><td>67000817</td><td>0.06450485</td></tr><tr><td>67000818</td><td>0.05985461</td></tr><tr><td>67000819</td><td>0.30334175</td></tr><tr><td>67000820</td><td>0.14946276</td></tr><tr><td>67000821</td><td>0.4366301</td></tr><tr><td>67000822</td><td>0.18804783</td></tr><tr><td>67000823</td><td>0.71071285</td></tr><tr><td>67000824</td><td>0.8496459</td></tr><tr><td>67000825</td><td>0.04400994</td></tr><tr><td>67000826</td><td>0.044457603</td></tr><tr><td>67000827</td><td>0.54064775</td></tr><tr><td>67000828</td><td>0.029573461</td></tr><tr><td>67000829</td><td>0.20230345</td></tr><tr><td>67000830</td><td>0.029407658</td></tr><tr><td>67000831</td><td>0.5420367</td></tr><tr><td>67000832</td><td>0.43174723</td></tr><tr><td>67000833</td><td>0.20069882</td></tr><tr><td>67000834</td><td>0.37903672</td></tr><tr><td>67000835</td><td>0.6256216</td></tr><tr><td>67000836</td><td>0.055079076</td></tr><tr><td>67000837</td><td>0.038699508</td></tr><tr><td>67000838</td><td>0.65529233</td></tr><tr><td>67000839</td><td>0.15167056</td></tr><tr><td>67000840</td><td>0.06893184</td></tr><tr><td>67000841</td><td>0.049085174</td></tr><tr><td>67000842</td><td>0.07768512</td></tr><tr><td>67000843</td><td>0.35482514</td></tr><tr><td>67000844</td><td>0.3203686</td></tr><tr><td>67000845</td><td>0.29638943</td></tr><tr><td>67000846</td><td>0.13101067</td></tr><tr><td>67000847</td><td>0.04427599</td></tr><tr><td>67000848</td><td>0.09010405</td></tr><tr><td>67000849</td><td>0.17003345</td></tr><tr><td>67000850</td><td>0.07698422</td></tr><tr><td>67000851</td><td>0.09000305</td></tr><tr><td>67000852</td><td>0.31798267</td></tr><tr><td>67000853</td><td>0.20568709</td></tr><tr><td>67000854</td><td>0.1031501</td></tr><tr><td>67000855</td><td>0.05437039</td></tr><tr><td>67000856</td><td>0.09547396</td></tr><tr><td>67000857</td><td>0.051469974</td></tr><tr><td>67000858</td><td>0.044457603</td></tr><tr><td>67000859</td><td>0.11623053</td></tr><tr><td>67000860</td><td>0.2873162</td></tr><tr><td>67000861</td><td>0.12960395</td></tr><tr><td>67000862</td><td>0.37955022</td></tr><tr><td>67000863</td><td>0.033062093</td></tr><tr><td>67000864</td><td>0.35942426</td></tr><tr><td>67000865</td><td>0.13108373</td></tr><tr><td>67000866</td><td>0.2642961</td></tr><tr><td>67000867</td><td>0.22333987</td></tr><tr><td>67000868</td><td>0.6489273</td></tr><tr><td>67000869</td><td>0.5762529</td></tr><tr><td>67000870</td><td>0.047762528</td></tr><tr><td>67000871</td><td>0.1146828</td></tr><tr><td>67000872</td><td>0.046569712</td></tr><tr><td>67000873</td><td>0.35806313</td></tr><tr><td>67000874</td><td>0.4823921</td></tr><tr><td>67000875</td><td>0.15156318</td></tr><tr><td>67000876</td><td>0.18448122</td></tr><tr><td>67000877</td><td>0.30857286</td></tr><tr><td>67000878</td><td>0.15231307</td></tr><tr><td>67000879</td><td>0.2673321</td></tr><tr><td>67000880</td><td>0.0567518</td></tr><tr><td>67000881</td><td>0.053320028</td></tr><tr><td>67000882</td><td>0.054108992</td></tr><tr><td>67000883</td><td>0.20390975</td></tr><tr><td>67000884</td><td>0.40743804</td></tr><tr><td>67000885</td><td>0.044086993</td></tr><tr><td>67000886</td><td>0.17934427</td></tr><tr><td>67000887</td><td>0.08808646</td></tr><tr><td>67000888</td><td>0.53205866</td></tr><tr><td>67000889</td><td>0.27157974</td></tr><tr><td>67000890</td><td>0.1322897</td></tr><tr><td>67000891</td><td>0.062017046</td></tr><tr><td>67000892</td><td>0.5917367</td></tr><tr><td>67000893</td><td>0.08956553</td></tr><tr><td>67000894</td><td>0.13730423</td></tr><tr><td>67000895</td><td>0.07846484</td></tr><tr><td>67000896</td><td>0.1456961</td></tr><tr><td>67000897</td><td>0.81425214</td></tr><tr><td>67000898</td><td>0.045296583</td></tr><tr><td>67000899</td><td>0.19632487</td></tr><tr><td>67000900</td><td>0.094540775</td></tr><tr><td>67000901</td><td>0.50330615</td></tr><tr><td>67000902</td><td>0.46093744</td></tr><tr><td>67000903</td><td>0.08180667</td></tr><tr><td>67000904</td><td>0.07015057</td></tr><tr><td>67000905</td><td>0.09738426</td></tr><tr><td>67000906</td><td>0.15088293</td></tr><tr><td>67000907</td><td>0.10619748</td></tr><tr><td>67000908</td><td>0.06252874</td></tr><tr><td>67000909</td><td>0.19018267</td></tr><tr><td>67000910</td><td>0.51836646</td></tr><tr><td>67000911</td><td>0.416335</td></tr><tr><td>67000912</td><td>0.49022368</td></tr><tr><td>67000913</td><td>0.03238082</td></tr><tr><td>67000914</td><td>0.71298563</td></tr><tr><td>67000915</td><td>0.21151544</td></tr><tr><td>67000916</td><td>0.17432521</td></tr><tr><td>67000917</td><td>0.40514994</td></tr><tr><td>67000918</td><td>0.10660433</td></tr><tr><td>67000919</td><td>0.21776891</td></tr><tr><td>67000920</td><td>0.5824346</td></tr><tr><td>67000921</td><td>0.2776854</td></tr><tr><td>67000922</td><td>0.5091201</td></tr><tr><td>67000923</td><td>0.27598795</td></tr><tr><td>67000924</td><td>0.031671688</td></tr><tr><td>67000925</td><td>0.06274859</td></tr><tr><td>67000926</td><td>0.60634106</td></tr><tr><td>67000927</td><td>0.06272741</td></tr><tr><td>67000928</td><td>0.14528632</td></tr><tr><td>67000929</td><td>0.043610644</td></tr><tr><td>67000930</td><td>0.11335962</td></tr><tr><td>67000931</td><td>0.12581612</td></tr><tr><td>67000932</td><td>0.2588133</td></tr><tr><td>67000933</td><td>0.13327256</td></tr><tr><td>67000934</td><td>0.057096403</td></tr><tr><td>67000935</td><td>0.13137804</td></tr><tr><td>67000936</td><td>0.04400994</td></tr><tr><td>67000937</td><td>0.28340864</td></tr><tr><td>67000938</td><td>0.20293556</td></tr><tr><td>67000939</td><td>0.04227892</td></tr><tr><td>67000940</td><td>0.18843727</td></tr><tr><td>67000941</td><td>0.114014156</td></tr><tr><td>67000942</td><td>0.37059665</td></tr><tr><td>67000943</td><td>0.40197995</td></tr><tr><td>67000944</td><td>0.08386732</td></tr><tr><td>67000945</td><td>0.2096225</td></tr><tr><td>67000946</td><td>0.09917698</td></tr><tr><td>67000947</td><td>0.07104237</td></tr><tr><td>67000948</td><td>0.031671688</td></tr><tr><td>67000949</td><td>0.5189199</td></tr><tr><td>67000950</td><td>0.04450182</td></tr><tr><td>67000951</td><td>0.12708168</td></tr><tr><td>67000952</td><td>0.18117127</td></tr><tr><td>67000953</td><td>0.21978688</td></tr><tr><td>67000954</td><td>0.17381793</td></tr><tr><td>67000955</td><td>0.035467945</td></tr><tr><td>67000956</td><td>0.1464891</td></tr><tr><td>67000957</td><td>0.23464547</td></tr><tr><td>67000958</td><td>0.48481494</td></tr><tr><td>67000959</td><td>0.029407658</td></tr><tr><td>67000960</td><td>0.66992044</td></tr><tr><td>67000961</td><td>0.044237286</td></tr><tr><td>67000962</td><td>0.039432045</td></tr><tr><td>67000963</td><td>0.03941862</td></tr><tr><td>67000964</td><td>0.30082533</td></tr><tr><td>67000965</td><td>0.70814466</td></tr><tr><td>67000966</td><td>0.07528223</td></tr><tr><td>67000967</td><td>0.04400994</td></tr><tr><td>67000968</td><td>0.031263947</td></tr><tr><td>67000969</td><td>0.56604797</td></tr><tr><td>67000970</td><td>0.07334289</td></tr><tr><td>67000971</td><td>0.45961285</td></tr><tr><td>67000972</td><td>0.19932182</td></tr><tr><td>67000973</td><td>0.09158718</td></tr><tr><td>67000974</td><td>0.031899624</td></tr><tr><td>67000975</td><td>0.12623626</td></tr><tr><td>67000976</td><td>0.050664835</td></tr><tr><td>67000977</td><td>0.16280004</td></tr><tr><td>67000978</td><td>0.3470286</td></tr><tr><td>67000979</td><td>0.21279825</td></tr><tr><td>67000980</td><td>0.1184127</td></tr><tr><td>67000981</td><td>0.06320694</td></tr><tr><td>67000982</td><td>0.3500357</td></tr><tr><td>67000983</td><td>0.05109864</td></tr><tr><td>67000984</td><td>0.0562654</td></tr><tr><td>67000985</td><td>0.1340669</td></tr><tr><td>67000986</td><td>0.118089415</td></tr><tr><td>67000987</td><td>0.13818473</td></tr><tr><td>67000988</td><td>0.1123676</td></tr><tr><td>67000989</td><td>0.14234199</td></tr><tr><td>67000990</td><td>0.09999504</td></tr><tr><td>67000991</td><td>0.06561258</td></tr><tr><td>67000992</td><td>0.050516218</td></tr><tr><td>67000993</td><td>0.5426839</td></tr><tr><td>67000994</td><td>0.21256988</td></tr><tr><td>67000995</td><td>0.04227892</td></tr><tr><td>67000996</td><td>0.12278745</td></tr><tr><td>67000997</td><td>0.6741667</td></tr><tr><td>67000998</td><td>0.23698369</td></tr><tr><td>67000999</td><td>0.4458911</td></tr></tbody></table>Showing the first 1000 rows.</div>"]}}],"execution_count":35}],"metadata":{"name":"Model 2020-09-29 - GBT, 44% (AUC 0.74461)","notebookId":3883965750819175},"nbformat":4,"nbformat_minor":0}
